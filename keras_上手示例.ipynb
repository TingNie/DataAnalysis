{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n",
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# 用简单的数字数据集，测试一下，多层全连接网络\n",
    "digits = load_digits()\n",
    "print(digits.keys())\n",
    "data = digits.data\n",
    "target = digits.target\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "5    182\n",
       "1    182\n",
       "6    181\n",
       "4    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(target).value_counts() #种类比例，基本一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABLCAYAAABQtG2+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADPNJREFUeJzt3XtwFdUdB/DvjwBieKgRiM8QNKAM\nKtBiWxBQa5GCbQnSjhYsHayigE6lyFCgTtFqacsgWgUqI8ZHtPUJtBRQx0cKCCJTixXQFEUiCCoK\nSJBX4dc/dtk955Abk9y9u9np9zNzx7PZyz0/9+49d/d3z0NUFURElB5Nkg6AiIjqhw03EVHKsOEm\nIkoZNtxERCnDhpuIKGXYcBMRpQwbbiKilGkUDbeIFIjIfBHZKyKbRWRYAjHcJCJrROSAiDwcd/1G\nHMeJyDz/OOwRkTdFZGBCsZSLyDYR+UJEKkXkuiTiMOLpJCL7RaQ8ofpf9euv9h/vJhGHH8vVIrLB\n/8y8JyJ9Y66/2nkcFpH74ozBiKVYRBaLyE4R2S4i94tI0wTi6CIiL4vIbhHZKCJDclVXo2i4AcwC\ncBBAIYDhAOaISNeYY/gIwJ0AHoq5XldTAB8CuBjACQBuA/CUiBQnEMs0AMWq2gbADwDcKSJfTyCO\no2YBeCPB+gHgJlVt5T/OSSIAEekP4PcARgJoDaAfgPfjjME4Bq3gfW73AXg6zhgMswF8AuBUAN3h\nfXbGxBmA/0WxEMAiAAUARgEoF5HOuagv8YZbRFoCGArgNlWtVtXlAP4K4CdxxqGqz6nqAgCfxVlv\nDXHsVdWpqvqBqh5R1UUANgGIvcFU1XWqeuDopv84O+44AO8KE8AuAC8lUX8jczuAO1R1lX+ObFXV\nrQnG80N4DeeyhOrvCOApVd2vqtsBLAUQ94XfuQBOAzBTVQ+r6ssAViBH7VjiDTeAzgAOq2ql8be1\niP/AN0oiUgjvGK1LqP7ZIvIlgHcAbAOwOIEY2gC4A8D4uOuuwTQR2SEiK0TkkrgrF5E8AD0BtPNv\nx7f4qYHj447F8FMAj2py82fcC+BqEckXkdMBDITXeMdJMvztvFxU1hga7lYAdjt/2w3vFvD/mog0\nA/A4gEdU9Z0kYlDVMfDei74AngNwoPZ/kRO/ATBPVT9MoG7TRABnATgdwFwAfxORuO9ACgE0g3eV\n2xdeaqAHgF/FHAcAQESK4KUmHkmifl8FvAu9LwBsAbAGwIKYY3gH3l3HBBFpJiKXwzsu+bmorDE0\n3NUA2jh/awNgTwKxNBoi0gTAY/By/zclGYt/67ccwBkARsdZt4h0B/AdADPjrLcmqvq6qu5R1QOq\n+gi8W+FBMYexz//vfaq6TVV3ALg7gTiOGgFguapuSqJy/3PyPLyLipYA2gI4Cd5vALFR1UMASgFc\nAWA7vLvDp+B9kUSuMTTclQCaikgn42/dkFBqoDEQEQEwD97V1VD/pGgMmiL+HPclAIoBVInIdgC3\nAhgqIv+MOY6aKGq+Rc5dhao74TUGjWVazxFI9mq7AMCZAO73v1A/A1CGBL7IVPUtVb1YVU9W1QHw\n7s5W56KuxBtuVd0L79vyDhFpKSIXARgM72ozNiLSVERaAMgDkCciLZLoUuSbA6ALgO+r6r6venIu\niEh7v8tZKxHJE5EBAH4M4OWYQ5kL78uiu//4E4C/AxgQZxAicqKIDDh6XojIcHi9OZ6PMw5fGYCb\n/ffoJAC3wOvNECsR6Q0vbZRUbxL4dxybAIz235cT4eXc18Ydi4hc4J8f+SJyK7xeLg/npDJVTfwB\n71tzAYC9AKoADEsghqkIe04cfUxNII4Oft374aWRjj6GxxxHO3i5w13wcof/BnB9IzhXpgIoT6De\ndvC6Iu7xj8kqAP0TOgbN4HWB2wXvtvyPAFokEMcDAB5rBOdEdwCvAtgJYAe8L5L2CcQx3Y+hGsAS\nACW5qkv8ComIKCUST5UQEVH9sOEmIkoZNtxERCnDhpuIKGVy0t2tf5MfZfzF88sh37S2l816IChX\nHtpr7btl0LXW9uF1mSdje/HI08f0p60tDtfo/2wMyuOWXW3t63ztmrq+TJ3iyCtsH5TvWT0/42uN\nHWGPu2lS8WakcZi2PGvPMLCu1+MZX7vryuHW9hlDM3e5z/Z92T6ud1C+fcyj1r45nUrq+jJ1iuPz\nkb2C8ht3zanza1+6brC1ffw1YQ/Owx9/Uu84anPaqnBA8eqtRda+2t4HV33jqJra29reMGp2xte+\ncIo9RqugbGVkcWyc+S1re8mVM4Ly+oOF1r5Jj4+wtoumvhZZHC7zM71hmv2+zOz7l4xxuTHVFEdN\neMVNRJQybLiJiFKGDTcRUcrEPqS76ZjtGfc9s/tr1nafP//L2q64IJ6ZK6/vaU8rXIFo6333l2dl\n3Ddt23eD8tgH7ZHE9cnp1oWZL1zSc4a1r8vcCUG5uTN3411urhnRxeX+BrJ2QphL7Tbdnhv/FGTO\nWTZEi11HMu4zf38ZsmaUtW9/lT2R5TkRrmngHo9Jp94dlAcvneA+PVJm3nbhyOnWvkvXhYtU/bzY\nniK91bCP7Bcqiy6mfr3sPH7nZi2D8vqD9nPdPPyAqd0ji8P8PQQApkwOZ+gYt8zOcY9fdI213eJ8\ndzLU+uMVNxFRyrDhJiJKmVhSJeYt1ytdF1r7zn7yxqB8zu/sW8zFb75gbS/velVQrq1rYEPc+8Fl\nQdmN0aw36roHPmcv6tKqKvwuLZtgp2zq3kGtbszjPXaB3fWwqCJMQ9y3eYW1z425BKsii2n8H+xu\niGbXww5PbLSf3NVe8jHqc8JkprC+qtvd4QjrnXfP3db2z275RVAumh9tqshldmW8ucNF1r7m2ByU\nF67qYe2revtUa7vEeG62tky003KVj5oL3bSy9i3Ya2+b7ZDbTbMu8ozzzUyNAEBpy+qgfO+Zn1r7\n+ve010B55Wa7a2VD8IqbiChl2HATEaUMG24iopSJJce9abSZl7Lz1mZO1807uUOJq647KSiXjIsu\nPuDYLk2mT79RYG0XZLmoWsm4zDlhs4ueOwVA1Mzj3cQ59ubQarebpvtbRLY5XXNYe2lLuwvojPIw\nT1m4sMrat3prO2v7jKHZxdH6tXDZxN/usPPnZUXh7w0Xjqz7kO6GMHOxZnc3ANjRLS8od3ytvbWv\nIXnbujpysZ3Hfr/0uKA8+uRy+8l2Tzm8bXSdy/ZYudM+3FAZdkt0f5sa1ONyazvb43Oobbjur5nT\ndrlxuOaf9e2gXFDRsFh4xU1ElDJsuImIUiapxXADbT6IsvNUw63fd3pQLm1pdyurbURd1MyRYWYX\nNM+e2OJYtfT8oDzJGTW3pPcl1nb+/OxuQc1Z/9z0WP7814Ny2Sw7jXL2yhsRJfNW+smyy6x9kyeE\n58SQcfZ6yRVl0Y6s3dO7Y8Z904aHx6p0lH277qZ3lvfvEJSzTRO4o3hrSxVMecseOZif4XkNccyI\nxeKwW57b/c89jtmep2aaxh3Fe/CEsNxxjt1tdV+5fX5UdwgnALSTsPWIpYH/joiIEsKGm4goZdhw\nExGlTCw57rZrwzy228XN7IKFQrt70wOdn7C2B6/I3Wxok9vmbrh0bfKc/+eyorC7pLvSDJ61N/MX\ntQnKUXdJM1fmGHiCPcS930S7P+RHmRfxqZE7453ZBbDU7UrlTDRnalGUu5z/KTPt4eRd+4Tvhbs6\n0JIhN1jbZl6+IazPhMOcIXKuc+5snm13j2xfHuahm/fPKiTMLb3C2h5vdM2d8T27O2B9VuKpr/Nu\neNva/vXscDWZ6iLnt6h+9mZJPc/T2rjnh8V5X/oXOkPeX2loZjvEK24iopRhw01ElDJsuImIUiaW\nHLeZ83vmdnv4dOHCcEXswSfXvoq52T8y297fbm65NtnmLGuru8+Lmae8rG2ldQC4tI3R5znLVUbM\nYeeAncNzVx05ZnVx1C+n6eZwzb7bxa0/z/jvzGHngJ3jj5qbhx/e6dWMz21ducvazvbcNPtcu32T\nKx/qGZS7TLKnAHBX4inuFe6v5aeCutmx09pccuVDQTmX0/wC9ufF/A0IAAa9cFpQ3jDe/v9vUdU8\n0jjqauswe+rZeS/ZK16VVGR/fHjFTUSUMmy4iYhSJvYh7+7qD+ZQWncYbbfpdve/Uz6ObsUPdwiw\neUu68LMezrOj7XZ26NxweP3ktvat38iqvkH5Hyu7WvsK3hJru93i94JytrfnV420Z0c0h3i7XTjH\nTrRXy6kv99ibXdXcW3pztkQ4qZKopyIwVzhxV54xZ+nruPQ6e9+6NZHGYXK74eXfEaYW3RWiXBdO\nCWcxLEB23UXdBa7XHywMylHPFukyzxf32G968cGg7E6XcPykfdZ2XJNr/LePvRhwSQ66R/KKm4go\nZdhwExGlDBtuIqKUEVVNOgYiIqoHXnETEaUMG24iopRhw01ElDJsuImIUoYNNxFRyrDhJiJKGTbc\nREQpw4abiChl2HATEaUMG24iopRhw01ElDJsuImIUoYNNxFRyrDhJiJKGTbcREQpw4abiChl2HAT\nEaUMG24iopRhw01ElDJsuImIUoYNNxFRyrDhJiJKGTbcREQp8z/cc18vLwtX6QAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf307470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#随机选出每一类的一个样本看看长什么样子\n",
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 1\n",
    "for y, cla in enumerate(classes):\n",
    "    idxs = np.flatnonzero(target == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(digits.images[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cla)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n",
      "(1437, 10)\n",
      "(360, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "X = data\n",
    "y = target\n",
    "\n",
    "#分隔数据集合，分为train,test集合\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "# 对label进行one-hot编码\n",
    "y_train_label = LabelBinarizer().fit_transform(y_train)\n",
    "y_test_label = LabelBinarizer().fit_transform(y_test)\n",
    "# 或者用 one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_label.shape)\n",
    "print(y_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1437/1437 [==============================] - 0s 237us/step - loss: 2.5802 - acc: 0.1392\n",
      "Epoch 2/50\n",
      "1437/1437 [==============================] - 0s 39us/step - loss: 2.2799 - acc: 0.2011\n",
      "Epoch 3/50\n",
      "1437/1437 [==============================] - 0s 38us/step - loss: 2.1287 - acc: 0.2526\n",
      "Epoch 4/50\n",
      "1437/1437 [==============================] - 0s 47us/step - loss: 2.0249 - acc: 0.3132\n",
      "Epoch 5/50\n",
      "1437/1437 [==============================] - 0s 45us/step - loss: 1.9399 - acc: 0.3890\n",
      "Epoch 6/50\n",
      "1437/1437 [==============================] - ETA: 0s - loss: 1.9327 - acc: 0.420 - 0s 42us/step - loss: 1.8652 - acc: 0.4718\n",
      "Epoch 7/50\n",
      "1437/1437 [==============================] - 0s 40us/step - loss: 1.7966 - acc: 0.5532\n",
      "Epoch 8/50\n",
      "1437/1437 [==============================] - 0s 40us/step - loss: 1.7325 - acc: 0.6221\n",
      "Epoch 9/50\n",
      "1437/1437 [==============================] - 0s 51us/step - loss: 1.6729 - acc: 0.6715\n",
      "Epoch 10/50\n",
      "1437/1437 [==============================] - 0s 51us/step - loss: 1.6202 - acc: 0.7105\n",
      "Epoch 11/50\n",
      "1437/1437 [==============================] - 0s 55us/step - loss: 1.5714 - acc: 0.7418\n",
      "Epoch 12/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 1.5256 - acc: 0.7613\n",
      "Epoch 13/50\n",
      "1437/1437 [==============================] - 0s 56us/step - loss: 1.4818 - acc: 0.7752\n",
      "Epoch 14/50\n",
      "1437/1437 [==============================] - 0s 57us/step - loss: 1.4399 - acc: 0.7898\n",
      "Epoch 15/50\n",
      "1437/1437 [==============================] - 0s 55us/step - loss: 1.4006 - acc: 0.7982\n",
      "Epoch 16/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 1.3634 - acc: 0.8065\n",
      "Epoch 17/50\n",
      "1437/1437 [==============================] - 0s 49us/step - loss: 1.3263 - acc: 0.8149\n",
      "Epoch 18/50\n",
      "1437/1437 [==============================] - 0s 51us/step - loss: 1.2915 - acc: 0.8212\n",
      "Epoch 19/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 1.2579 - acc: 0.8288\n",
      "Epoch 20/50\n",
      "1437/1437 [==============================] - 0s 42us/step - loss: 1.2255 - acc: 0.8344\n",
      "Epoch 21/50\n",
      "1437/1437 [==============================] - 0s 54us/step - loss: 1.1940 - acc: 0.8392\n",
      "Epoch 22/50\n",
      "1437/1437 [==============================] - 0s 50us/step - loss: 1.1644 - acc: 0.8448\n",
      "Epoch 23/50\n",
      "1437/1437 [==============================] - 0s 47us/step - loss: 1.1354 - acc: 0.8462\n",
      "Epoch 24/50\n",
      "1437/1437 [==============================] - 0s 40us/step - loss: 1.1075 - acc: 0.8490\n",
      "Epoch 25/50\n",
      "1437/1437 [==============================] - 0s 40us/step - loss: 1.0806 - acc: 0.8539\n",
      "Epoch 26/50\n",
      "1437/1437 [==============================] - 0s 54us/step - loss: 1.0551 - acc: 0.8573\n",
      "Epoch 27/50\n",
      "1437/1437 [==============================] - 0s 49us/step - loss: 1.0306 - acc: 0.8608\n",
      "Epoch 28/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 1.0070 - acc: 0.8650\n",
      "Epoch 29/50\n",
      "1437/1437 [==============================] - 0s 50us/step - loss: 0.9841 - acc: 0.8699\n",
      "Epoch 30/50\n",
      "1437/1437 [==============================] - 0s 51us/step - loss: 0.9624 - acc: 0.8699\n",
      "Epoch 31/50\n",
      "1437/1437 [==============================] - 0s 50us/step - loss: 0.9412 - acc: 0.8727\n",
      "Epoch 32/50\n",
      "1437/1437 [==============================] - 0s 52us/step - loss: 0.9210 - acc: 0.8789\n",
      "Epoch 33/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 0.9016 - acc: 0.8831\n",
      "Epoch 34/50\n",
      "1437/1437 [==============================] - 0s 55us/step - loss: 0.8826 - acc: 0.8845\n",
      "Epoch 35/50\n",
      "1437/1437 [==============================] - 0s 58us/step - loss: 0.8645 - acc: 0.8859\n",
      "Epoch 36/50\n",
      "1437/1437 [==============================] - 0s 56us/step - loss: 0.8471 - acc: 0.8935\n",
      "Epoch 37/50\n",
      "1437/1437 [==============================] - 0s 49us/step - loss: 0.8304 - acc: 0.8942\n",
      "Epoch 38/50\n",
      "1437/1437 [==============================] - 0s 54us/step - loss: 0.8144 - acc: 0.8970\n",
      "Epoch 39/50\n",
      "1437/1437 [==============================] - 0s 52us/step - loss: 0.7993 - acc: 0.8998\n",
      "Epoch 40/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 0.7845 - acc: 0.9019\n",
      "Epoch 41/50\n",
      "1437/1437 [==============================] - 0s 58us/step - loss: 0.7702 - acc: 0.9019\n",
      "Epoch 42/50\n",
      "1437/1437 [==============================] - 0s 54us/step - loss: 0.7566 - acc: 0.9040\n",
      "Epoch 43/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 0.7434 - acc: 0.9047\n",
      "Epoch 44/50\n",
      "1437/1437 [==============================] - 0s 49us/step - loss: 0.7304 - acc: 0.9068\n",
      "Epoch 45/50\n",
      "1437/1437 [==============================] - 0s 49us/step - loss: 0.7179 - acc: 0.9088\n",
      "Epoch 46/50\n",
      "1437/1437 [==============================] - 0s 45us/step - loss: 0.7057 - acc: 0.9116\n",
      "Epoch 47/50\n",
      "1437/1437 [==============================] - 0s 56us/step - loss: 0.6943 - acc: 0.9130\n",
      "Epoch 48/50\n",
      "1437/1437 [==============================] - 0s 55us/step - loss: 0.6827 - acc: 0.9123\n",
      "Epoch 49/50\n",
      "1437/1437 [==============================] - 0s 52us/step - loss: 0.6717 - acc: 0.9151\n",
      "Epoch 50/50\n",
      "1437/1437 [==============================] - 0s 53us/step - loss: 0.6612 - acc: 0.9144\n",
      "最后的验证集评估结果：\n",
      "360/360 [==============================] - 0s 281us/step\n",
      "[0.67832274238268531, 0.90555556118488312]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "# input(None,64) - hidden(64,10) - output(10)\n",
    "# 序贯模型（Sequential）\n",
    "model = Sequential()\n",
    "model.add(Dense(100,input_dim=64))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10, activation='softmax')) #多分类\n",
    "# 编译\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 训练\n",
    "model.fit(X_train, y_train_label,\n",
    "          epochs=50,\n",
    "          batch_size=150)\n",
    "# 评估\n",
    "print('最后的验证集评估结果：')\n",
    "score = model.evaluate(X_test, y_test_label, batch_size=150)\n",
    "print(score)\n",
    "# loss , acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 2.3824 - acc: 0.1000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 2.3331 - acc: 0.1100\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 2.2907 - acc: 0.1000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 2.2918 - acc: 0.1300\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 2.2909 - acc: 0.1300\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 2.2925 - acc: 0.1000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 2.2823 - acc: 0.1700\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.2786 - acc: 0.1500\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 2.2657 - acc: 0.1300\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 2.3399 - acc: 0.1300\n",
      "20/20 [==============================] - 1s 69ms/step\n",
      "验证集评估结果：\n",
      "[2.3388915061950684, 0.05000000074505806]\n"
     ]
    }
   ],
   "source": [
    "#类似VGG的卷积神经网络：\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "# 输入层\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 输出层\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'] )\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32) \n",
    "print('验证集评估结果：')\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
